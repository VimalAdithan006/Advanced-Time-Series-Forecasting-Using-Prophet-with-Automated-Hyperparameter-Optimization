{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941de11d-01f5-4057-be26-82441549e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Time Series Forecasting with Prophet and Hyperparameter Optimization\n",
    "# Single-file Jupyter notebook style script that: \n",
    "# 1) programmatically generates a 3+ year hourly synthetic dataset with daily, weekly, yearly seasonality, trend shifts, and holidays\n",
    "# 2) fits a baseline Prophet model\n",
    "# 3) runs a systematic Grid Search over three Prophet hyperparameters using rolling-origin validation\n",
    "# 4) trains final model and reports MAE, RMSE, MAPE and visualizations\n",
    "\n",
    "# Notes:\n",
    "# - Requires: pandas, numpy, matplotlib, prophet (or fbprophet), sklearn\n",
    "# - If `prophet` import fails, try `fbprophet` (uncomment fallback)\n",
    "# - This script is ready to paste into a Jupyter cell and run top-to-bottom.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from itertools import product\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Try import Prophet\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "except Exception:\n",
    "    try:\n",
    "        from fbprophet import Prophet\n",
    "    except Exception as e:\n",
    "        raise ImportError('Prophet is required. Install with `pip install prophet` or `pip install fbprophet`.')\n",
    "\n",
    "# -------------------------------\n",
    "# 1) Synthetic data generation\n",
    "# -------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Generate hourly date index for ~3.5 years (~3 years + buffer)\n",
    "start = pd.to_datetime('2018-01-01')\n",
    "periods = 24 * 3 * 365 + 24 * 180  # ~3.5 years of hourly data\n",
    "date_index = pd.date_range(start=start, periods=periods, freq='H')\n",
    "\n",
    "# Base components\n",
    "def daily_seasonality(t, amplitude=10):\n",
    "    # 24-hour cycle using sin\n",
    "    return amplitude * np.sin(2 * np.pi * (t.hour / 24.0))\n",
    "\n",
    "def weekly_seasonality(t, amplitude=5):\n",
    "    # weekly pattern using day of week\n",
    "    return amplitude * ((t.dayofweek >= 5) * 1.0)  # weekend bump\n",
    "\n",
    "def yearly_seasonality(t, amplitude=3):\n",
    "    # approximate yearly cycle using dayofyear\n",
    "    return amplitude * np.sin(2 * np.pi * (t.dayofyear / 365.25))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'ds': date_index})\n",
    "\n",
    "# Trend piecewise linear with changepoints (abrupt shifts)\n",
    "# start with a base linear trend\n",
    "base_trend = 0.001 * np.arange(len(df))\n",
    "\n",
    "# Introduce random abrupt trend shifts at specified dates\n",
    "changepoint_dates = [pd.Timestamp('2019-06-01'), pd.Timestamp('2020-09-15'), pd.Timestamp('2021-05-01')]\n",
    "trend_shift = np.zeros(len(df))\n",
    "for cp in changepoint_dates:\n",
    "    idx = df.index[df['ds'] >= cp]\n",
    "    if len(idx) > 0:\n",
    "        # add a slope change after changepoint\n",
    "        shift_amount = np.random.uniform(-0.0008, 0.0015)\n",
    "        trend_shift[idx] += shift_amount * np.arange(len(idx))\n",
    "\n",
    "trend = base_trend + np.concatenate(([0], np.cumsum(np.diff(base_trend) + np.concatenate((np.zeros(1), trend_shift[:-1])))))\n",
    "\n",
    "# Build y from components\n",
    "y = []\n",
    "for t in df['ds']:\n",
    "    val = 50.0  # base level\n",
    "    val += daily_seasonality(t, amplitude=12)\n",
    "    val += weekly_seasonality(t, amplitude=6)\n",
    "    val += yearly_seasonality(t, amplitude=4)\n",
    "    # add slowly changing trend (interpolate from computed trend)\n",
    "    val += trend[df.index[df['ds'] == t][0]]\n",
    "    y.append(val)\n",
    "\n",
    "# Convert to numpy\n",
    "y = np.array(y)\n",
    "\n",
    "# Add holiday spikes/dips (predefined simulated holidays)\n",
    "holidays = []\n",
    "# We'll create a list of holiday dates and add effects across windows\n",
    "holiday_list = [\n",
    "    {'name': 'new_year', 'month': 1, 'day': 1},\n",
    "    {'name': 'independence_day', 'month': 8, 'day': 15},\n",
    "    {'name': 'diwali_approx', 'month': 11, 'day': 4},\n",
    "    {'name': 'christmas', 'month': 12, 'day': 25}\n",
    "]\n",
    "\n",
    "# Simulate holiday effect as spike/dip in value for a small window\n",
    "for year in range(start.year, start.year + 5):\n",
    "    for h in holiday_list:\n",
    "        try:\n",
    "            d = pd.Timestamp(year=year, month=h['month'], day=h['day'])\n",
    "        except Exception:\n",
    "            continue\n",
    "        # add a holiday effect for +/- 12 hours\n",
    "        mask = (df['ds'] >= (d - pd.Timedelta(hours=12))) & (df['ds'] <= (d + pd.Timedelta(hours=12)))\n",
    "        effect = np.random.uniform(-15, 20)  # holiday can be negative or positive\n",
    "        y[mask.values] += effect * np.exp(-((np.arange(mask.sum()) - mask.sum()//2)**2) / (2*(4**2)))\n",
    "        holidays.append({'ds': d, 'holiday': h['name']})\n",
    "\n",
    "# Add heteroscedastic noise and small random outliers\n",
    "noise = np.random.normal(scale=3.5 + 0.005 * np.arange(len(df)), size=len(df))\n",
    "# occasional outliers\n",
    "outlier_idx = np.random.choice(np.arange(len(df)), size=int(0.001 * len(df)), replace=False)\n",
    "noise[outlier_idx] += np.random.choice([-40, 40], size=len(outlier_idx))\n",
    "\n",
    "y = y + noise\n",
    "\n",
    "# Compose final dataframe\n",
    "df['y'] = y\n",
    "\n",
    "# Sanity check\n",
    "print('Generated data points:', len(df))\n",
    "print(df.head())\n",
    "\n",
    "# Save CSV\n",
    "os.makedirs('/mnt/data', exist_ok=True)\n",
    "csv_path = '/mnt/data/synthetic_hourly_timeseries.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "print('Saved synthetic dataset to', csv_path)\n",
    "\n",
    "# -------------------------------\n",
    "# 2) Prepare Prophet-friendly data and holidays dataframe\n",
    "# -------------------------------\n",
    "# Build holidays DataFrame for Prophet\n",
    "hol_df = pd.DataFrame(holidays)\n",
    "if not hol_df.empty:\n",
    "    hol_df = hol_df.drop_duplicates().reset_index(drop=True)\n",
    "else:\n",
    "    hol_df = pd.DataFrame(columns=['ds', 'holiday'])\n",
    "\n",
    "# Prophet expects ds column as datetime and holiday names\n",
    "if not hol_df.empty:\n",
    "    hol_df['ds'] = pd.to_datetime(hol_df['ds'])\n",
    "\n",
    "# -------------------------------\n",
    "# 3) Train/test split (80/20)\n",
    "# -------------------------------\n",
    "split_idx = int(len(df) * 0.8)\n",
    "train_df = df.iloc[:split_idx].copy()\n",
    "test_df = df.iloc[split_idx:].copy()\n",
    "print('Train length:', len(train_df), 'Test length:', len(test_df))\n",
    "\n",
    "# -------------------------------\n",
    "# Utility: Forecast evaluation metrics\n",
    "# -------------------------------\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    denom = np.where(np.abs(y_true) < 1e-8, 1e-8, np.abs(y_true))\n",
    "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
    "\n",
    "# -------------------------------\n",
    "# 4) Baseline Prophet model\n",
    "# -------------------------------\n",
    "print('\\nFitting baseline Prophet model...')\n",
    "model = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=True, holidays=hol_df, interval_width=0.95)\n",
    "# set small changepoint_prior_scale as baseline\n",
    "model.changepoint_prior_scale = 0.05\n",
    "model.seasonality_prior_scale = 10.0\n",
    "model.holidays_prior_scale = 10.0\n",
    "\n",
    "model.fit(train_df[['ds', 'y']])\n",
    "\n",
    "# Create future for test period\n",
    "future = test_df[['ds']].copy()\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Evaluate baseline\n",
    "baseline_pred = forecast['yhat'].values\n",
    "base_mae = mean_absolute_error(test_df['y'].values, baseline_pred)\n",
    "base_rmse = np.sqrt(mean_squared_error(test_df['y'].values, baseline_pred))\n",
    "base_mape = mape(test_df['y'].values, baseline_pred)\n",
    "\n",
    "print('Baseline MAE: {:.4f}, RMSE: {:.4f}, MAPE: {:.4f}%'.format(base_mae, base_rmse, base_mape))\n",
    "\n",
    "# Plot baseline\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(test_df['ds'], test_df['y'], label='Actual', alpha=0.6)\n",
    "plt.plot(test_df['ds'], baseline_pred, label='Baseline Prophet Forecast', alpha=0.8)\n",
    "plt.legend()\n",
    "plt.title('Baseline Forecast vs Actual (Test set)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 5) Grid Search with Rolling Origin Validation\n",
    "# -------------------------------\n",
    "print('\\nStarting Grid Search with rolling-origin validation...')\n",
    "\n",
    "# Parameter grid (concise but representative)\n",
    "param_grid = {\n",
    "    'changepoint_prior_scale': [0.01, 0.05, 0.1, 0.5],\n",
    "    'seasonality_prior_scale': [1.0, 5.0, 10.0],\n",
    "    'holidays_prior_scale': [1.0, 5.0, 10.0]\n",
    "}\n",
    "\n",
    "# Rolling origin parameters\n",
    "n_splits = 3  # number of rolling validations; can increase\n",
    "min_train_size = int(len(train_df) * 0.6)\n",
    "horizon = len(test_df)  # evaluate on last test horizon for final ranking\n",
    "\n",
    "# Create split points (simple growing window)\n",
    "split_points = []\n",
    "start_idx = min_train_size\n",
    "increment = int((len(train_df) - min_train_size) / (n_splits))\n",
    "for i in range(n_splits):\n",
    "    train_end = start_idx + i * increment\n",
    "    if train_end + 24 > len(train_df):\n",
    "        break\n",
    "    split_points.append(train_end)\n",
    "\n",
    "if not split_points:\n",
    "    split_points = [min_train_size]\n",
    "\n",
    "# Evaluate combinations\n",
    "results = []\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    scores = []\n",
    "    for sp in split_points:\n",
    "        train_split = train_df.iloc[:sp].copy()\n",
    "        val_split = train_df.iloc[sp:sp + horizon].copy()\n",
    "        if len(val_split) < 24:\n",
    "            continue\n",
    "        m = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=True, holidays=hol_df, interval_width=0.95)\n",
    "        m.changepoint_prior_scale = params['changepoint_prior_scale']\n",
    "        m.seasonality_prior_scale = params['seasonality_prior_scale']\n",
    "        m.holidays_prior_scale = params['holidays_prior_scale']\n",
    "        try:\n",
    "            m.fit(train_split[['ds', 'y']])\n",
    "            # forecast validation horizon from val_split ds\n",
    "            future_val = val_split[['ds']].copy()\n",
    "            pred = m.predict(future_val)['yhat'].values\n",
    "            true = val_split['y'].values\n",
    "            rmse = np.sqrt(mean_squared_error(true, pred))\n",
    "            scores.append(rmse)\n",
    "        except Exception as e:\n",
    "            scores.append(np.nan)\n",
    "    # aggregate score\n",
    "    if len(scores) == 0:\n",
    "        mean_score = np.nan\n",
    "    else:\n",
    "        mean_score = np.nanmean(scores)\n",
    "    results.append({'params': params, 'mean_rmse': mean_score})\n",
    "    print('Tested:', params, '-> mean_rmse:', mean_score)\n",
    "\n",
    "# Sort results\n",
    "results_sorted = sorted(results, key=lambda x: (np.nan if x['mean_rmse'] is None else x['mean_rmse']))\n",
    "\n",
    "# Show top 5\n",
    "top_k = [r for r in results_sorted if not np.isnan(r['mean_rmse'])][:5]\n",
    "print('\\nTop parameter sets:')\n",
    "for i, r in enumerate(top_k):\n",
    "    print(i+1, r)\n",
    "\n",
    "# Choose best\n",
    "best = None\n",
    "for r in results_sorted:\n",
    "    if not np.isnan(r['mean_rmse']):\n",
    "        best = r\n",
    "        break\n",
    "\n",
    "if best is None:\n",
    "    # fallback to baseline hyperparams\n",
    "    best_params = {'changepoint_prior_scale': 0.05, 'seasonality_prior_scale': 10.0, 'holidays_prior_scale': 10.0}\n",
    "else:\n",
    "    best_params = best['params']\n",
    "\n",
    "print('\\nSelected best_params:', best_params)\n",
    "\n",
    "# -------------------------------\n",
    "# 6) Train final model on full training set & forecast test set\n",
    "# -------------------------------\n",
    "print('\\nTraining final model with best parameters on full training set...')\n",
    "final_model = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=True, holidays=hol_df, interval_width=0.95)\n",
    "final_model.changepoint_prior_scale = best_params['changepoint_prior_scale']\n",
    "final_model.seasonality_prior_scale = best_params['seasonality_prior_scale']\n",
    "final_model.holidays_prior_scale = best_params['holidays_prior_scale']\n",
    "\n",
    "final_model.fit(train_df[['ds','y']])\n",
    "future_test = test_df[['ds']].copy()\n",
    "final_forecast = final_model.predict(future_test)\n",
    "\n",
    "pred = final_forecast['yhat'].values\n",
    "true = test_df['y'].values\n",
    "final_mae = mean_absolute_error(true, pred)\n",
    "final_rmse = np.sqrt(mean_squared_error(true, pred))\n",
    "final_mape = mape(true, pred)\n",
    "\n",
    "metrics = {\n",
    "    'baseline': {'MAE': base_mae, 'RMSE': base_rmse, 'MAPE': base_mape},\n",
    "    'final': {'MAE': final_mae, 'RMSE': final_rmse, 'MAPE': final_mape}\n",
    "}\n",
    "\n",
    "print('\\nFinal metrics:')\n",
    "print(json.dumps(metrics, indent=2))\n",
    "\n",
    "# Save forecast and metrics\n",
    "out_dir = '/mnt/data/prophet_project_outputs'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "final_forecast[['ds','yhat','yhat_lower','yhat_upper']].to_csv(os.path.join(out_dir, 'final_forecast.csv'), index=False)\n",
    "with open(os.path.join(out_dir, 'metrics.json'), 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "print('Saved outputs to', out_dir)\n",
    "\n",
    "# -------------------------------\n",
    "# Plots for final model\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(test_df['ds'], true, label='Actual', alpha=0.6)\n",
    "plt.plot(test_df['ds'], pred, label='Final Prophet Forecast', alpha=0.9)\n",
    "plt.fill_between(test_df['ds'], final_forecast['yhat_lower'], final_forecast['yhat_upper'], alpha=0.2)\n",
    "plt.legend()\n",
    "plt.title('Final Forecast vs Actual (Test set)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot components\n",
    "fig = final_model.plot_components(final_forecast)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "summary_df = pd.DataFrame([{\n",
    "    'model': 'baseline',\n",
    "    'MAE': base_mae,\n",
    "    'RMSE': base_rmse,\n",
    "    'MAPE': base_mape\n",
    "}, {\n",
    "    'model': 'final',\n",
    "    'MAE': final_mae,\n",
    "    'RMSE': final_rmse,\n",
    "    'MAPE': final_mape\n",
    "}])\n",
    "\n",
    "print('\\nPerformance summary:')\n",
    "print(summary_df)\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv(os.path.join(out_dir, 'summary_metrics.csv'), index=False)\n",
    "\n",
    "# End of notebook\n",
    "print('\\nNotebook run complete. Files saved in /mnt/data and /mnt/data/prophet_project_outputs')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
